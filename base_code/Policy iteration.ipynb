{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":681,"status":"ok","timestamp":1712224128842,"user":{"displayName":"엔리더","userId":"07803193534854383371"},"user_tz":-540},"id":"lDrTy72DOkqu","outputId":"a4fca848-f92c-439e-96b9-53e0b9ca8e35"},"outputs":[{"output_type":"stream","name":"stdout","text":["The initial random policy is:\n","\n","| Up    | Up    | Right | +10   |\n","| Up    | WALL  | Down  | -10   |\n","| Up    | Left  | Down  | Right |\n","| Down  | Up    | Right | Down  |\n","\n","[[  0   0   0  10]\n"," [  0   0   0 -10]\n"," [  0   0   0   0]\n"," [  0   0   0   0]] \n","\n","During the policy iteration:\n","\n","| Up    | Right | Right | +10   |\n","| Up    | WALL  | Up    | -10   |\n","| Up    | Left  | Down  | Up    |\n","| Down  | Up    | Right | Down  |\n","\n","[[-99.99900475 -99.99900475   8.9         10.        ]\n"," [-99.99900475   0.         -99.99900475 -10.        ]\n"," [-99.99900475 -99.99900475 -99.99900475 -99.99900475]\n"," [-99.99900475 -99.99900475 -99.99900475 -99.99900475]] \n","\n","1146\n","| Right | Right | Right | +10   |\n","| Up    | WALL  | Up    | -10   |\n","| Up    | Left  | Up    | Up    |\n","| Down  | Up    | Right | Up    |\n","\n","[[-99.99902455   7.811        8.9         10.        ]\n"," [-99.99902455   0.           7.811      -10.        ]\n"," [-99.99902455 -99.99902455 -99.99902455 -10.9       ]\n"," [-99.99902455 -99.99902455 -99.99902455 -99.99902455]] \n","\n","1148\n","| Right | Right | Right | +10   |\n","| Up    | WALL  | Up    | -10   |\n","| Up    | Right | Up    | Left  |\n","| Up    | Up    | Up    | Up    |\n","\n","[[  6.73289      7.811        8.9         10.        ]\n"," [  5.6655611    0.           7.811      -10.        ]\n"," [  4.60890549   3.56281643   6.73289    -10.9       ]\n"," [-99.99908164   2.52718827 -12.67309    -11.791     ]] \n","\n","1154\n","The optimal policy is:\n","\n","| Right | Right | Right | +10   |\n","| Up    | WALL  | Up    | -10   |\n","| Up    | Right | Up    | Left  |\n","| Up    | Up    | Up    | Up    |\n","\n","1157\n"]}],"source":["import random\n","import numpy as np\n","\n","# Arguments\n","REWARD = -1 # constant reward for non-terminal states\n","REWARD2 = -1\n","DISCOUNT = 0.99\n","MAX_ERROR = 10**(-3)\n","\n","global counter\n","counter = 0\n","\n","# Set up the initial environment\n","NUM_ACTIONS = 4\n","ACTIONS = [(1, 0), (0, -1), (-1, 0), (0, 1)] # Down, Left, Up, Right\n","NUM_ROW = 4\n","NUM_COL = 4\n","U = [[0, 0, 0, 10], [0, 0, 0, -10], [0, 0, 0, 0], [0, 0, 0, 0]]\n","policy = [[random.randint(0, 3) for j in range(NUM_COL)] for i in range(NUM_ROW)] # construct a random policy\n","Value = np.matrix(U)\n","# Visualization\n","\n","\n","def printEnvironment(arr, policy=False):\n","    res = \"\"\n","    for r in range(NUM_ROW):\n","        res += \"|\"\n","        for c in range(NUM_COL):\n","            if r == c == 1:\n","                val = \"WALL\"\n","            elif r <= 1 and c == 3:\n","                val = \"+10\" if r == 0 else \"-10\"\n","            else:\n","                val = [\"Down\", \"Left\", \"Up\", \"Right\"][arr[r][c]]\n","            res += \" \" + val[:5].ljust(5) + \" |\" # format\n","        res += \"\\n\"\n","    print(res)\n","\n","\n","\n","# Get the utility of the state reached by performing the given action from the given state\n","def getU(U, r, c, action):\n","    dr, dc = ACTIONS[action]\n","    newR, newC = r+dr, c+dc\n","    if newR < 0 or newC < 0 or newR >= NUM_ROW or newC >= NUM_COL or (newR == newC == 1): # collide with the boundary or the wall\n","        return U[r][c]\n","    else:\n","        return U[newR][newC]\n","\n","# Calculate the utility of a state given an action\n","def calculateU(U, r, c, action):\n","    if r == 3 and c == 2:\n","       u = REWARD2\n","    else:\n","       u = REWARD\n","   # u += 0.1 * DISCOUNT * getU(U, r, c, (action-1)%4)\n","    u += 1 * DISCOUNT * getU(U, r, c, action)\n","   # u += 0.1 * DISCOUNT * getU(U, r, c, (action+1)%4)\n","    return u\n","\n","# Perform some simplified value iteration steps to get an approximation of the utilities\n","def policyEvaluation(policy, U):\n","    global counter\n","    while True:\n","        nextU = [[0, 0, 0, 10], [0, 0, 0, -10], [0, 0, 0, 0], [0, 0, 0, 0]]\n","        error = 0\n","        for r in range(NUM_ROW):\n","            for c in range(NUM_COL):\n","                if (r <= 1 and c == 3) or (r == c == 1):\n","                    continue\n","                nextU[r][c] = calculateU(U, r, c, policy[r][c]) # simplified Bellman update\n","                error = max(error, abs(nextU[r][c]-U[r][c]))\n","        U = nextU\n","        counter += 1\n","        if error < MAX_ERROR * (1-DISCOUNT) / DISCOUNT:\n","            break\n","    return U\n","\n","def policyIteration(policy, U):\n","    print(\"During the policy iteration:\\n\")\n","    while True:\n","        U = policyEvaluation(policy, U)\n","        unchanged = True\n","        for r in range(NUM_ROW):\n","            for c in range(NUM_COL):\n","                if (r <= 1 and c == 3) or (r == c == 1):\n","                    continue\n","                maxAction, maxU = None, -float(\"inf\")\n","                for action in range(NUM_ACTIONS):\n","                    u = calculateU(U, r, c, action)\n","                    if u > maxU:\n","                        maxAction, maxU = action, u\n","                if maxU > calculateU(U, r, c, policy[r][c]):\n","                    policy[r][c] = maxAction # the action that maximizes the utility\n","                    unchanged = False\n","        if unchanged:\n","            break\n","        printEnvironment(policy)\n","        print (np.matrix(U),'\\n')\n","        print (counter)\n","    return policy\n","\n","# Print the initial environment\n","print(\"The initial random policy is:\\n\")\n","printEnvironment(policy)\n","print (np.matrix(U),'\\n')\n","# Policy iteration\n","policy = policyIteration(policy, U)\n","\n","# Print the optimal policy\n","print(\"The optimal policy is:\\n\")\n","printEnvironment(policy)\n","\n","print(counter)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPs24gaXVs8v4MBtWoIzHNB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}