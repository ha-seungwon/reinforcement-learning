{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNhtFvU3HaGG9icFvxdUJwW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ItU4c-w3Oyqm","executionInfo":{"status":"ok","timestamp":1712220125254,"user_tz":-540,"elapsed":5,"user":{"displayName":"엔리더","userId":"07803193534854383371"}},"outputId":"80e87f7a-0288-4d58-ee7f-716c77363a9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["The initial U is:\n","\n","| 0     | 0     | 0     | +1    |\n","| 0     | WALL  | 0     | -1    |\n","| 0     | 0     | 0     | 0     |\n","| 0     | 0     | 0     | 0     |\n","\n","During the value iteration:\n","\n","| -1.0  | -1.0  | 8.9   | +1    |\n","| -1.0  | WALL  | -1.0  | -1    |\n","| -1.0  | -1.0  | -1.0  | -1.0  |\n","| -1.0  | -1.0  | -1.0  | -1.0  |\n","\n","| -1.99 | 7.811 | 8.9   | +1    |\n","| -1.99 | WALL  | 7.811 | -1    |\n","| -1.99 | -1.99 | -1.99 | -1.99 |\n","| -1.99 | -1.99 | -1.99 | -1.99 |\n","\n","| 6.732 | 7.811 | 8.9   | +1    |\n","| -2.97 | WALL  | 7.811 | -1    |\n","| -2.97 | -2.97 | 6.732 | -2.97 |\n","| -2.97 | -2.97 | -2.97 | -2.97 |\n","\n","| 6.732 | 7.811 | 8.9   | +1    |\n","| 5.665 | WALL  | 7.811 | -1    |\n","| -3.94 | 5.665 | 6.732 | 5.665 |\n","| -3.94 | -3.94 | 5.665 | -3.94 |\n","\n","| 6.732 | 7.811 | 8.9   | +1    |\n","| 5.665 | WALL  | 7.811 | -1    |\n","| 4.608 | 5.665 | 6.732 | 5.665 |\n","| -4.90 | 4.608 | 5.665 | 4.608 |\n","\n","| 6.732 | 7.811 | 8.9   | +1    |\n","| 5.665 | WALL  | 7.811 | -1    |\n","| 4.608 | 5.665 | 6.732 | 5.665 |\n","| 3.562 | 4.608 | 5.665 | 4.608 |\n","\n","| 6.732 | 7.811 | 8.9   | +1    |\n","| 5.665 | WALL  | 7.811 | -1    |\n","| 4.608 | 5.665 | 6.732 | 5.665 |\n","| 3.562 | 4.608 | 5.665 | 4.608 |\n","\n","The optimal policy is:\n","\n","| Right | Right | Right | +1    |\n","| Up    | WALL  | Up    | -1    |\n","| Up    | Right | Up    | Left  |\n","| Up    | Up    | Up    | Left  |\n","\n","7\n"]}],"source":["# Arguments\n","REWARD = -1 # constant reward for non-terminal states\n","DISCOUNT = 0.99\n","MAX_ERROR = 10**(-3)\n","\n","global counter\n","counter = 0\n","\n","# Set up the initial environment\n","NUM_ACTIONS = 4\n","ACTIONS = [(1, 0), (0, -1), (-1, 0), (0, 1)] # Down, Left, Up, Right\n","NUM_ROW = 4\n","NUM_COL = 4\n","U = [[0, 0, 0, 10], [0, 0, 0, -10], [0, 0, 0, 0], [0, 0, 0, 0]]\n","\n","# Visualization\n","def printEnvironment(arr, policy=False):\n","    res = \"\"\n","    for r in range(NUM_ROW):\n","        res += \"|\"\n","        for c in range(NUM_COL):\n","            if r == c == 1:\n","                val = \"WALL\"\n","            elif r <= 1 and c == 3:\n","                val = \"+1\" if r == 0 else \"-1\"\n","            else:\n","                if policy:\n","                    val = [\"Down\", \"Left\", \"Up\", \"Right\"][arr[r][c]]\n","                else:\n","                    val = str(arr[r][c])\n","            res += \" \" + val[:5].ljust(5) + \" |\" # format\n","        res += \"\\n\"\n","    print(res)\n","\n","# Get the utility of the state reached by performing the given action from the given state\n","def getU(U, r, c, action):\n","    dr, dc = ACTIONS[action]\n","    newR, newC = r+dr, c+dc\n","    if newR < 0 or newC < 0 or newR >= NUM_ROW or newC >= NUM_COL or (newR == newC == 1): # collide with the boundary or the wall\n","        return U[r][c]\n","    else:\n","        return U[newR][newC]\n","\n","# Calculate the utility of a state given an action\n","def calculateU(U, r, c, action):\n","    u = REWARD\n","#    u += 0.1 * DISCOUNT * getU(U, r, c, (action-1)%4)\n","    u += 1 * DISCOUNT * getU(U, r, c, action)\n","#    u += 0.1 * DISCOUNT * getU(U, r, c, (action+1)%4)\n","    return u\n","\n","def valueIteration(U):\n","    print(\"During the value iteration:\\n\")\n","    global counter\n","    while True:\n","        nextU = [[0, 0, 0, 10], [0, 0, 0, -10], [0, 0, 0, 0], [0, 0, 0, 0]]\n","        error = 0\n","        for r in range(NUM_ROW):\n","            for c in range(NUM_COL):\n","                if (r <= 1 and c == 3) or (r == c == 1):\n","                    continue\n","                nextU[r][c] = max([calculateU(U, r, c, action) for action in range(NUM_ACTIONS)]) # Bellman update\n","                error = max(error, abs(nextU[r][c]-U[r][c]))\n","        U = nextU\n","        printEnvironment(U)\n","        counter += 1\n","        if error < MAX_ERROR * (1-DISCOUNT) / DISCOUNT:\n","            break\n","    return U\n","\n","# Get the optimal policy from U\n","def getOptimalPolicy(U):\n","    policy = [[-1, -1, -1, -1] for i in range(NUM_ROW)]\n","    for r in range(NUM_ROW):\n","        for c in range(NUM_COL):\n","            if (r <= 1 and c == 3) or (r == c == 1):\n","                continue\n","            # Choose the action that maximizes the utility\n","            maxAction, maxU = None, -float(\"inf\")\n","            for action in range(NUM_ACTIONS):\n","                u = calculateU(U, r, c, action)\n","                if u > maxU:\n","                    maxAction, maxU = action, u\n","            policy[r][c] = maxAction\n","    return policy\n","\n","# Print the initial environment\n","print(\"The initial U is:\\n\")\n","printEnvironment(U)\n","\n","# Value iteration\n","U = valueIteration(U)\n","\n","# Get the optimal policy from U and print it\n","policy = getOptimalPolicy(U)\n","print(\"The optimal policy is:\\n\")\n","printEnvironment(policy, True)\n","print (counter)"]}]}